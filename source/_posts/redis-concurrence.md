---
title: node.js 请求 redis 的性能优化和 redis 的管道和事务机制
date: 2019-03-13 17:16:44
tags: [Node.js, redis]
---

最近撸了一个简略版的 MQ。其中大量涉及了 redis 的请求，虽然 redis 速度够快，但是在大量请求下延迟也是相当夸张的。

了解了下 Redis 的一些原理，首先 Redis 是用 c 语言编写，其交互数据都存储于内存中。也就是说在普通的 set、get 请求中，基于获取数据的时间消耗其实相当的小。(基本可以当做在内存中读一个变量的时间)。而对应的时间消耗的大户就是网络 IO 时间。

当然我还是太年亲了，大佬表示想法太简单，贴上某大佬的解释:

1. socket IO 导致的上下文切换开销
   * 熟悉OS／Linux的童鞋都知道，一次 redis 请求在客户端和服务端分别至少会存在一次 read() 和一次 write() ，作为系统调用，read／write 的成本高于普通的函数调用，因此，在单个命令重复调用场景下，大量的 read/write 系统调用会产生明显的系统开销。
2. 指令执行开销
   - Redis 采用 C 实现，使用了轻量级的 hash 表、skipList 跳表等数据结构实现了高效的缓存。因此，单条执行大多数指令的成本非常低。因此，相对而言，IO 的开销显得更加无法忽略。
3. (高并发下) 资源竞争和系统调度调度开销
   * 一般来说，这一开销在客户端的影响更为明显。在高压力下，如果采用循环( loop )方式调用多次指令来完成某个服务请求，那么在高并发下，多个请求会在多个线程中同时竞争 redis 连接资源多次，导致连接池压力增加，线程上下文切换更加频发，最终会导致请求 RTT(round-trip time) 急剧恶化。如果每个请求只抢占一次 redis 连接并通过批量执行的方式一次处理多个请求，则单次请求的 RTT 会有显著提升。
   * 在服务端，因为我们通常将 redis 绑定到 CPU (不管是通过物理机还是通过docker)，因此一般而言不存在系统调度／资源竞争的开销。但是由于 redis 对 qps 敏感，如果因为客户端使用不合理而造成 qps 放大效应，则 redis 可能更早触及性能瓶颈而导致系统响应严重下降。

from https://www.jianshu.com/p/75137d23ae4a



---

文章从四种方式来分析批量请求对性能的影响。

- 批量get/set(multi get/set)
- 管道(pipelining)
- 事务(transaction)
- 基于事务的管道(transaction in pipelining)

> 虽然个人很不认同第三种，刚开始很不理解为什么文章实验结果出来 3、4 类型的时间基本相似。后面看了 ioredis 的说明才明白。可能他调用的 module 本身默认在事务的情况下开启了管道。



---

## 小 TEST

简单的测试请求数对时间的影响。

因为主要排除网络请求因素导致的时间影响。因此选用了`mset` 作为测试方式。

即单条请求为 `set` 多条请求为 `mset`。

```
当前为总数: 100 | 每次填充数量为 1 | 平均时间为 107.13333333333334 ms
当前为总数: 100 | 每次填充数量为 10 | 平均时间为 34 ms
当前为总数: 100 | 每次填充数量为 20 | 平均时间为 34 ms
当前为总数: 100 | 每次填充数量为 30 | 平均时间为 26.066666666666666 ms
当前为总数: 100 | 每次填充数量为 40 | 平均时间为 25.033333333333335 ms
当前为总数: 100 | 每次填充数量为 50 | 平均时间为 24.2 ms
当前为总数: 100 | 每次填充数量为 80 | 平均时间为 19.933333333333334 ms
当前为总数: 100 | 每次填充数量为 100 | 平均时间为 19.433333333333334 ms
当前为总数: 100 | 每次填充数量为 150 | 平均时间为 18.466666666666665 ms
当前为总数: 100 | 每次填充数量为 200 | 平均时间为 15.066666666666666 ms
当前为总数: 100 | 每次填充数量为 250 | 平均时间为 15.333333333333334 ms
当前为总数: 100 | 每次填充数量为 300 | 平均时间为 16.3 ms
当前为总数: 100 | 每次填充数量为 500 | 平均时间为 13.133333333333333 ms
当前为总数: 100 | 每次填充数量为 750 | 平均时间为 13.266666666666667 ms
当前为总数: 100 | 每次填充数量为 1000 | 平均时间为 13.633333333333333 ms
当前为总数: 100 | 每次填充数量为 1250 | 平均时间为 12.133333333333333 ms
当前为总数: 100 | 每次填充数量为 1500 | 平均时间为 11.466666666666667 ms
当前为总数: 500 | 每次填充数量为 1 | 平均时间为 375.8 ms
当前为总数: 500 | 每次填充数量为 10 | 平均时间为 89.66666666666667 ms
当前为总数: 500 | 每次填充数量为 20 | 平均时间为 83.76666666666667 ms
当前为总数: 500 | 每次填充数量为 30 | 平均时间为 67.33333333333333 ms
当前为总数: 500 | 每次填充数量为 40 | 平均时间为 57.6 ms
当前为总数: 500 | 每次填充数量为 50 | 平均时间为 59.13333333333333 ms
当前为总数: 500 | 每次填充数量为 80 | 平均时间为 51.7 ms
当前为总数: 500 | 每次填充数量为 100 | 平均时间为 54.86666666666667 ms
当前为总数: 500 | 每次填充数量为 150 | 平均时间为 58.1 ms
当前为总数: 500 | 每次填充数量为 200 | 平均时间为 48.1 ms
当前为总数: 500 | 每次填充数量为 250 | 平均时间为 44.766666666666666 ms
当前为总数: 500 | 每次填充数量为 300 | 平均时间为 48.233333333333334 ms
当前为总数: 500 | 每次填充数量为 500 | 平均时间为 48.266666666666666 ms
当前为总数: 500 | 每次填充数量为 750 | 平均时间为 44.8 ms
当前为总数: 500 | 每次填充数量为 1000 | 平均时间为 50.3 ms
当前为总数: 500 | 每次填充数量为 1250 | 平均时间为 48.63333333333333 ms
当前为总数: 500 | 每次填充数量为 1500 | 平均时间为 49.43333333333333 ms
当前为总数: 1000 | 每次填充数量为 1 | 平均时间为 770.9666666666667 ms
当前为总数: 1000 | 每次填充数量为 10 | 平均时间为 218.5 ms
当前为总数: 1000 | 每次填充数量为 20 | 平均时间为 155.46666666666667 ms
当前为总数: 1000 | 每次填充数量为 30 | 平均时间为 140.73333333333332 ms
当前为总数: 1000 | 每次填充数量为 40 | 平均时间为 130.1 ms
当前为总数: 1000 | 每次填充数量为 50 | 平均时间为 127.66666666666667 ms
当前为总数: 1000 | 每次填充数量为 80 | 平均时间为 127.2 ms
当前为总数: 1000 | 每次填充数量为 100 | 平均时间为 121.7 ms
当前为总数: 1000 | 每次填充数量为 150 | 平均时间为 124.63333333333334 ms
当前为总数: 1000 | 每次填充数量为 200 | 平均时间为 131.03333333333333 ms
当前为总数: 1000 | 每次填充数量为 250 | 平均时间为 122.63333333333334 ms
当前为总数: 1000 | 每次填充数量为 300 | 平均时间为 129.9 ms
当前为总数: 1000 | 每次填充数量为 500 | 平均时间为 136.6 ms
当前为总数: 1000 | 每次填充数量为 750 | 平均时间为 133.2 ms
当前为总数: 1000 | 每次填充数量为 1000 | 平均时间为 134.03333333333333 ms
当前为总数: 1000 | 每次填充数量为 1250 | 平均时间为 138.7 ms
当前为总数: 1000 | 每次填充数量为 1500 | 平均时间为 135.86666666666667 ms
当前为总数: 2000 | 每次填充数量为 1 | 平均时间为 1643.9333333333334 ms
当前为总数: 2000 | 每次填充数量为 10 | 平均时间为 483.23333333333335 ms
当前为总数: 2000 | 每次填充数量为 20 | 平均时间为 378.7 ms
当前为总数: 2000 | 每次填充数量为 30 | 平均时间为 359.26666666666665 ms
当前为总数: 2000 | 每次填充数量为 40 | 平均时间为 363.6333333333333 ms
当前为总数: 2000 | 每次填充数量为 50 | 平均时间为 356.76666666666665 ms
当前为总数: 2000 | 每次填充数量为 80 | 平均时间为 361.73333333333335 ms
当前为总数: 2000 | 每次填充数量为 100 | 平均时间为 366.93333333333334 ms
当前为总数: 2000 | 每次填充数量为 150 | 平均时间为 378.76666666666665 ms
当前为总数: 2000 | 每次填充数量为 200 | 平均时间为 386.4 ms
当前为总数: 2000 | 每次填充数量为 250 | 平均时间为 389.8 ms
当前为总数: 2000 | 每次填充数量为 300 | 平均时间为 402.5 ms
当前为总数: 2000 | 每次填充数量为 500 | 平均时间为 430.3 ms
当前为总数: 2000 | 每次填充数量为 750 | 平均时间为 412.46666666666664 ms
当前为总数: 2000 | 每次填充数量为 1000 | 平均时间为 417.5 ms
当前为总数: 2000 | 每次填充数量为 1250 | 平均时间为 433.6 ms
当前为总数: 2000 | 每次填充数量为 1500 | 平均时间为 442.1666666666667 ms
```

首先说明 Node 其实很不适合做这个类似计时的事情，单线程容易被各种因素影响时间。但是大部分基本可以可以看出效果。

1. redis 网络请求的时间差不多占用了总时间的 70 % 以上。
2. 批量请求在达到 redis 的系统瓶颈之后速度极具下降。而 redis 的运行方式为单线程，盲目的加大批量信息只会造成 redis 的其他请求被堵塞。



所以批量请求并不是万金油，更不是解决 redis 所有问题的银弹。

实际场景还是按照业务量和 redis 的性能对批量的量级进行调整。

> 我这个测试场景是基于虚拟机的服务器，总内存只有 512 MB。所以瓶颈在 几千的请求就出现了。实际 redis 的服务器支持 1 万  qps 还是妥妥的没问题。



## Demo

我这边使用的 redis 包是 ioredis [https://www.npmjs.com/package/ioredis]()。

其实功能 README 都有说明。这里做一下笔记。

## 批量请求命令

批量请求命令主要有:

1. mset
2. mget
3. hmset
4. hmget

### mset

```javascript
let result = await redis.mset({ key1: 'value1', key2: 'value2' });
let result = await redis.mset(key1, 'value1', key2, 'value2');
result; // [ 'ok', 'ok' ]
```

### mget

```javascript
let result = await redis.mget([ 'key1', 'key2' ]);
let result = await redis.mget('key1', 'key2');
result; // [ 'value1', 'value2' ]
```

### hmset

```javascript
await redis.hmset('key', { k1: 'v1', k2: 'v2' })
await reids.hmset('key', new Map([['k1', 'v1'], ['k2', 'v2']]))
await redis.hmset('key', 'k1', 'v1', 'k2', 'v2')
```

### hmget

```javascript
await redis.hmget('key', [ 'k1', 'k2' ]);
await redis.hmget('key', 'k1', 'k2');
```



## 管道(Pipelining)

 redis 的管道通俗的来说就是将所有请求打包一个命令数组，在服务器上触发命令，并将结果包装成一个数组返回到客户端。

```javascript
const pipeline = redis.pipeline();
pipeline.set('foo', 'bar');
pipeline.del('cc');
let result = await pipeline.exec();
redis;
// [ [ null, 'ok'], [ null , 'ok'] ]
```

返回的 result 被包装成由 [ err, result ] 组成的数组。

管道默认是不支持事务的，也就是无论是否有命令报错，所有命令都会依次请求一次。

所以需要自己根据返回的 result 处理错误的命令。

管道命令也支持菊花写法：

```javascript
await redis.pipeline().set('foo', 'bar').del('cc').exec();
```

还能支持数组式的写法

```javascript
await redis.pipeline([
    [ 'set', 'foo', 'bar' ],
    [ 'del', 'cc' ]
]).exec();
```

### 事务(Transaction)

事务一直以来给我两个印象:

1. 错误回退。
2. 低性能。

好在 redis 是单进程系统，所以不会因为事务来导致锁表锁行等一些严重降低性能的行为。

这里主要说明的是，redis 对待两种不同的错误类型有两种不同的策略。

第一类是代码错误或者系统错误。

指的是某个代码命令有误或者系统错误。后者例如系统故障、内存不足等我们最担心的错误类型。

对于这些错误在执行 exec 时，会被 redis 拒绝。

而另一类错误则属于逻辑错误：

```
> multi
OK
> set key world
query
> incr key
query
> exec
```

这些错误不会影响别的入队的命令。

**对于这一类逻辑错误，redis 的执行方式是除了错误的那条命令别的命令都正常执行。**



ioredis 默认对事物开启管道：

```javascript
redis.multi().set('foo', 'new value').exec(function (err, results) {
});
```

因为 ioredis 并未提供 discard 命令。因此可以理解成 ioredis 的开发者是强烈推荐使用默认(管道)的方式来执行事务。

不开启管道的办法:

```javascript
redis.multi({ pipeline: false });
redis.set('foo', 'bar');
redis.get('foo');
redis.exec(function (err, result) {
  // result === [[null, 'OK'], [null, 'bar']]
});
```



